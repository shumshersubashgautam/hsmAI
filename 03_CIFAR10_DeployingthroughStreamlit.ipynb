{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJHIbdY4r9TNx+w04Be43C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shumshersubashgautam/hsmAI/blob/main/CIFAR10_DeployingthroughStreamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "_ZdUdDxKFzEF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q1SpiwEz51Re",
        "outputId": "807e88cc-1c9d-462d-d821-a25037c86010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "(50000, 32, 32, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 15, 15, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 2, 2, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73418 (286.79 KB)\n",
            "Trainable params: 73418 (286.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 10s 5ms/step - loss: 1.5784 - accuracy: 0.4207 - val_loss: 1.2922 - val_accuracy: 0.5412\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2077 - accuracy: 0.5732 - val_loss: 1.1048 - val_accuracy: 0.6158\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0548 - accuracy: 0.6318 - val_loss: 1.0304 - val_accuracy: 0.6418\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9593 - accuracy: 0.6655 - val_loss: 1.0221 - val_accuracy: 0.6506\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8909 - accuracy: 0.6894 - val_loss: 0.9244 - val_accuracy: 0.6822\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8342 - accuracy: 0.7088 - val_loss: 0.9035 - val_accuracy: 0.6916\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7900 - accuracy: 0.7235 - val_loss: 0.9572 - val_accuracy: 0.6778\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7568 - accuracy: 0.7353 - val_loss: 0.8599 - val_accuracy: 0.7042\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7185 - accuracy: 0.7503 - val_loss: 0.8573 - val_accuracy: 0.7111\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6905 - accuracy: 0.7591 - val_loss: 0.8956 - val_accuracy: 0.7002\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6638 - accuracy: 0.7675 - val_loss: 0.9045 - val_accuracy: 0.6978\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6388 - accuracy: 0.7755 - val_loss: 0.8875 - val_accuracy: 0.7019\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6130 - accuracy: 0.7852 - val_loss: 0.9396 - val_accuracy: 0.6973\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5866 - accuracy: 0.7949 - val_loss: 0.9143 - val_accuracy: 0.7065\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5694 - accuracy: 0.8004 - val_loss: 0.9002 - val_accuracy: 0.7015\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5461 - accuracy: 0.8067 - val_loss: 0.9112 - val_accuracy: 0.7107\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5265 - accuracy: 0.8138 - val_loss: 0.9374 - val_accuracy: 0.7095\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5094 - accuracy: 0.8198 - val_loss: 0.9511 - val_accuracy: 0.7103\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4914 - accuracy: 0.8267 - val_loss: 1.0093 - val_accuracy: 0.6934\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4741 - accuracy: 0.8305 - val_loss: 1.0253 - val_accuracy: 0.6937\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4585 - accuracy: 0.8362 - val_loss: 1.0281 - val_accuracy: 0.7006\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4432 - accuracy: 0.8428 - val_loss: 1.0271 - val_accuracy: 0.7005\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4263 - accuracy: 0.8494 - val_loss: 1.0387 - val_accuracy: 0.7022\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4199 - accuracy: 0.8505 - val_loss: 1.0319 - val_accuracy: 0.7060\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4047 - accuracy: 0.8557 - val_loss: 1.0918 - val_accuracy: 0.7006\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3911 - accuracy: 0.8602 - val_loss: 1.1284 - val_accuracy: 0.6849\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3814 - accuracy: 0.8635 - val_loss: 1.0981 - val_accuracy: 0.7076\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3647 - accuracy: 0.8701 - val_loss: 1.1432 - val_accuracy: 0.7009\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3578 - accuracy: 0.8741 - val_loss: 1.1965 - val_accuracy: 0.6973\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3447 - accuracy: 0.8743 - val_loss: 1.1825 - val_accuracy: 0.6990\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3356 - accuracy: 0.8796 - val_loss: 1.2688 - val_accuracy: 0.7004\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3238 - accuracy: 0.8829 - val_loss: 1.2496 - val_accuracy: 0.6924\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3205 - accuracy: 0.8849 - val_loss: 1.2748 - val_accuracy: 0.6964\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3081 - accuracy: 0.8896 - val_loss: 1.3166 - val_accuracy: 0.6889\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2995 - accuracy: 0.8912 - val_loss: 1.3464 - val_accuracy: 0.6967\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2934 - accuracy: 0.8944 - val_loss: 1.4121 - val_accuracy: 0.6768\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2829 - accuracy: 0.8960 - val_loss: 1.3911 - val_accuracy: 0.6968\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2804 - accuracy: 0.8992 - val_loss: 1.4014 - val_accuracy: 0.6867\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2698 - accuracy: 0.9026 - val_loss: 1.4522 - val_accuracy: 0.6887\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2697 - accuracy: 0.9026 - val_loss: 1.4388 - val_accuracy: 0.6981\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2574 - accuracy: 0.9074 - val_loss: 1.4692 - val_accuracy: 0.6918\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2607 - accuracy: 0.9052 - val_loss: 1.5040 - val_accuracy: 0.6893\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2425 - accuracy: 0.9114 - val_loss: 1.5497 - val_accuracy: 0.6926\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2405 - accuracy: 0.9127 - val_loss: 1.6183 - val_accuracy: 0.6876\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2359 - accuracy: 0.9138 - val_loss: 1.6243 - val_accuracy: 0.6855\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2311 - accuracy: 0.9161 - val_loss: 1.6597 - val_accuracy: 0.6818\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2313 - accuracy: 0.9163 - val_loss: 1.6615 - val_accuracy: 0.6812\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2240 - accuracy: 0.9174 - val_loss: 1.7435 - val_accuracy: 0.6826\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2140 - accuracy: 0.9205 - val_loss: 1.7038 - val_accuracy: 0.6831\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2099 - accuracy: 0.9241 - val_loss: 1.7701 - val_accuracy: 0.6781\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2067 - accuracy: 0.9251 - val_loss: 1.7221 - val_accuracy: 0.6936\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2084 - accuracy: 0.9233 - val_loss: 1.7803 - val_accuracy: 0.6841\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1987 - accuracy: 0.9281 - val_loss: 1.8120 - val_accuracy: 0.6914\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1982 - accuracy: 0.9280 - val_loss: 1.8842 - val_accuracy: 0.6840\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1897 - accuracy: 0.9305 - val_loss: 1.9400 - val_accuracy: 0.6881\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1871 - accuracy: 0.9326 - val_loss: 1.9676 - val_accuracy: 0.6866\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1942 - accuracy: 0.9302 - val_loss: 2.0005 - val_accuracy: 0.6807\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1769 - accuracy: 0.9353 - val_loss: 1.9501 - val_accuracy: 0.6868\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1899 - accuracy: 0.9321 - val_loss: 1.9237 - val_accuracy: 0.6916\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1827 - accuracy: 0.9343 - val_loss: 1.9448 - val_accuracy: 0.6955\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1811 - accuracy: 0.9347 - val_loss: 1.9885 - val_accuracy: 0.6872\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1739 - accuracy: 0.9372 - val_loss: 2.0355 - val_accuracy: 0.6865\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1721 - accuracy: 0.9382 - val_loss: 2.0265 - val_accuracy: 0.6846\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1702 - accuracy: 0.9381 - val_loss: 2.0233 - val_accuracy: 0.6848\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1652 - accuracy: 0.9406 - val_loss: 2.1641 - val_accuracy: 0.6840\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1659 - accuracy: 0.9411 - val_loss: 2.1773 - val_accuracy: 0.6805\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1652 - accuracy: 0.9402 - val_loss: 2.2134 - val_accuracy: 0.6897\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1610 - accuracy: 0.9416 - val_loss: 2.2200 - val_accuracy: 0.6850\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1534 - accuracy: 0.9454 - val_loss: 2.2209 - val_accuracy: 0.6816\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1539 - accuracy: 0.9443 - val_loss: 2.2865 - val_accuracy: 0.6766\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1600 - accuracy: 0.9419 - val_loss: 2.3031 - val_accuracy: 0.6740\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1538 - accuracy: 0.9444 - val_loss: 2.3784 - val_accuracy: 0.6819\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1546 - accuracy: 0.9443 - val_loss: 2.3074 - val_accuracy: 0.6824\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1465 - accuracy: 0.9474 - val_loss: 2.2786 - val_accuracy: 0.6849\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1378 - accuracy: 0.9496 - val_loss: 2.4095 - val_accuracy: 0.6848\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1544 - accuracy: 0.9448 - val_loss: 2.3879 - val_accuracy: 0.6854\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1493 - accuracy: 0.9463 - val_loss: 2.4109 - val_accuracy: 0.6799\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1421 - accuracy: 0.9489 - val_loss: 2.2978 - val_accuracy: 0.6835\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1410 - accuracy: 0.9485 - val_loss: 2.4473 - val_accuracy: 0.6873\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1363 - accuracy: 0.9505 - val_loss: 2.5443 - val_accuracy: 0.6818\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1430 - accuracy: 0.9494 - val_loss: 2.5558 - val_accuracy: 0.6826\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1408 - accuracy: 0.9508 - val_loss: 2.4627 - val_accuracy: 0.6903\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1426 - accuracy: 0.9497 - val_loss: 2.4246 - val_accuracy: 0.6873\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1333 - accuracy: 0.9531 - val_loss: 2.5675 - val_accuracy: 0.6835\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1384 - accuracy: 0.9517 - val_loss: 2.6307 - val_accuracy: 0.6757\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1322 - accuracy: 0.9528 - val_loss: 2.6343 - val_accuracy: 0.6801\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1338 - accuracy: 0.9538 - val_loss: 2.5578 - val_accuracy: 0.6842\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1242 - accuracy: 0.9569 - val_loss: 2.7168 - val_accuracy: 0.6755\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1299 - accuracy: 0.9539 - val_loss: 2.6854 - val_accuracy: 0.6769\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1309 - accuracy: 0.9547 - val_loss: 2.6840 - val_accuracy: 0.6831\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1287 - accuracy: 0.9550 - val_loss: 2.6520 - val_accuracy: 0.6850\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1250 - accuracy: 0.9556 - val_loss: 2.9032 - val_accuracy: 0.6697\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1259 - accuracy: 0.9558 - val_loss: 2.7432 - val_accuracy: 0.6798\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1302 - accuracy: 0.9548 - val_loss: 2.7281 - val_accuracy: 0.6797\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1263 - accuracy: 0.9552 - val_loss: 2.7474 - val_accuracy: 0.6797\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1269 - accuracy: 0.9547 - val_loss: 2.7808 - val_accuracy: 0.6866\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1217 - accuracy: 0.9565 - val_loss: 2.8662 - val_accuracy: 0.6730\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1261 - accuracy: 0.9560 - val_loss: 2.8398 - val_accuracy: 0.6741\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1184 - accuracy: 0.9598 - val_loss: 2.8715 - val_accuracy: 0.6793\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1252 - accuracy: 0.9579 - val_loss: 2.7890 - val_accuracy: 0.6839\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[3 8 8 0 6]\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is enabled\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Import necessary packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Check the shape of the data\n",
        "print(X_train.shape)\n",
        "\n",
        "# Reshape y_train into a one-dimensional array\n",
        "y_train = y_train.ravel()\n",
        "\n",
        "# Define class names\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# Function to plot sample images\n",
        "def plot_sample(X, y, index):\n",
        "    plt.figure(figsize=(15, 2))\n",
        "    plt.imshow(X[index])\n",
        "    plt.xlabel(classes[y[index]])\n",
        "    plt.show()\n",
        "\n",
        "# Plot a sample image\n",
        "plot_sample(X_train, y_train, 53)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
        "\n",
        "# Predict the classes for test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred[:4]\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_classes = [np.argmax(element) for element in y_pred]\n",
        "y_classes[:5]\n",
        "\n",
        "# Reshape y_test for comparison\n",
        "y_test = y_test.reshape(-1,)\n",
        "print(y_test[:5])\n",
        "\n",
        "# Save the model\n",
        "model.save(\"my_model100.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "vjBMOmFt5_q6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QJS5Vk76UVR",
        "outputId": "21887249-a1d7-4e16-b177-ca7dded20809"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.614s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEVtPOrz6awF",
        "outputId": "b512fb55-9c54-4189-adb2-b32733994834"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.147.23.255\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.535s\n",
            "your url is: https://slimy-parks-buy.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b7evcuktF_s9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
